<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>shibadog site</title>
    <link>https://pages.shibadog.net/</link>
    <description>Recent content on shibadog site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Wed, 17 May 2023 00:00:00 +0900</lastBuildDate><atom:link href="https://pages.shibadog.net/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>spring boot 3 trace</title>
      <link>https://pages.shibadog.net/posts/008_survery_results/</link>
      <pubDate>Wed, 17 May 2023 00:00:00 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/008_survery_results/</guid>
      <description>背景 spring boot3になってからtraceの構成が変わった。
sleuth から micrometer observationを使う用に代わり、opentelemetryが入ってきて関係性が変わったのでそれを把握したい。
micrometer observationの解説は優秀なブログがすでにあるのでそちらに任せることにする。
https://programacho.com/blog/a10b96ec9d79/
ここでは、このmicrometerの裏側を把握することを目的とする。
全体感から見た各種ライブラリの役割 ▲ なにかのdiagramのルールにのっとって書いているわけではなく、雰囲気で矢印と図形の形を変えている。
意味はあるが公のルールではないのでご注意。
tracer layerの詳細 この領域はトレーサー層と呼ぶらしい。
ここは、exporter（braveではreporter）を使って実際のトレース情報を伝送する部分の実装であったり、アプリケーション間のトレース情報をつなぐための処理を行う実装が存在する。
braveはもともとのspring cloudに存在する実装であり、zipkinのb3ヘッダのみに対応している。
opentelemetryでは、opentelemetryが定義する伝送プロトコル（なんだっけ？）とb3のどちらにも対応しており、ここをpropagatorと呼んでおり差し替え可能となっている。
w3c → W3CTraceContextPropagator b3 → B3Propagator opentelemetryを使った場合のexporter layer詳細 Opentelemetryに対応したトレース参照用のツールはいくつか存在する。
これ以外にも、上記zipkinの例から以下のような構造になっていることが伺える。
参考資料のmakingさんの資料にある通り、spring boot 3.0.Xまでは、exporterのauto configに対応している（つまり何もBean登録しなくても設定だけで使えるやつ）のはzipkinとwavefrontのみとなっている。
しかし、opentelemetry自体はいろいろなexporterに対応しており、自力でBean登録をすることで異なるサービスにtraceを伝送することが可能になっている。
braveを使った場合のexporter layer(reporter)詳細 tracerをopentelemetryではなく従来のbraveを選択することも可能となっている。
この場合でも伝送先を切り替えることが可能となっている。
Opentelemetryに対応しているElastic APMに入れてみる 本リポジトリでは、前章でまとめた依存のうち以下のような組み合わせでアプリケーションを作成している。
tracer layer -&amp;gt; opentelemetry exporter layer -&amp;gt; opentelemetry tracerの記録先は Elastic APMを利用している。
詳しくは ../../pom.xml を参照いただきたいが、traceにかかわる依存は以下の通り。
&amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;io.micrometer&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;micrometer-tracing-bridge-otel&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;io.opentelemetry&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;opentelemetry-exporter-otlp&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; spring bootに関しては、3.0.x系であるため、そのままではopentelemetry exporterのauto configに対応していない。</description>
    </item>
    
    <item>
      <title>CentOSの事情</title>
      <link>https://pages.shibadog.net/posts/009_centos/</link>
      <pubDate>Fri, 03 Mar 2023 00:00:00 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/009_centos/</guid>
      <description>背景 業務で利用するLinux Serverを新規で作成することになった。
既存のLinux Serverの横に追加することになっているため、追加するサーバのOSも併せようと考えたが、現在CentOSはバージョンアップ方針が変わっており、そのまま採用すべきではないのではないか、となった。
適切なOSを選定するとともに、CentOSの事情を把握しておきたいため、調査する。
CentOSの事情 元々の流れ CentOSは Red Hat Enterprise Linux（以降RHEL）というディストリビューションの系列に属しており、RHELと機能的に互換性があることを目指したフリーのLinuxディストリビューションである。
RHELに含まれているソフトウェアの中にはOSSで無償公開しているため、これをもとに、商標や商用パッケージをのぞいたものをリビルドして提供している。そのため、「RHELクローン」と呼ばれることもある。(CentOS自体は公式には否定している)
最初期ではRHELを提供するレッドハットは関わっていなかったが、2014年からCentOSを正式に支援していくことを表明していた。
しかし、2020/12/8にCentOSからCentOS Streamに開発の主軸を移動し、CentOS Linux 8のサポートを2021年に停止している。RHEL 9に対応するCentOS Linux 9は提供さず、今後はCentOS Stream 9の提供とする。
Red Hat Enterprise Linux派生ディストリビューション Red Hat Enterprise Linux派生ディストリビューション
RHELには様々なディストリビューションが存在する。大きくは、まず同社がメンテナを行っているFedora Linuxがある。これは、もともとはRHELの無償版であった。
しかし、Fedoraはサポート期間が比較的短く、実験的なリリース方針であったため、長期サポートを望むユーザとしては利用に適していなかった。
RHELはコンパイル済みのものを無償提供していないが、完全なソースコードを公開しているため、これを入手し再コンパイルすることで派生ディストリビューションの作成が行われている。
CentOSのサポート情報 CentOS
Version 完全更新期限 メンテナス更新期限 6 6.10(最終) 2017年 Q2 2020/11/30 7 7.9-2009(最新) 2020年 Q4 2024/06/30 8 8.5.2111(最終) 2021年12月 2021/12/31 CentOS Stream CentOS StreamはRHELとFedora Linuxの中間を目指したディストリビューション。
Fedoraは実験的なリリースを取り込み、RHELの将来のメジャーリリースのベースとなるアップストリームプロジェクトであったが、CentOS StreamはRHELの次のバージョンとなる変更を取り入れたRHELのプレビューとなる。
このような性質の変更があったため、重要なビジネスアプリケーションやプロダクション環境での使用は推奨されておらずRHELが進められる。
元々のCentOSの性質としては、他のRHELと同様にコードのリビルドから生成されたものであり、個別メンテナンスであったため、今回の変更で性質ががらりと変わる。
やはり商用利用を考えた場合、（本質的にはRHELを使え、なのだが）あまり利用は推奨されるべきものではなくなるという見解があちらこちらで見られた。
派生ディストリビューションについて CentOSの事情を鑑み（結局ただ乗りになるのだが。。。）、同じ要件をかなえるためのディストリビューションが多数生まれている。
もし、無償版を利用するならばこの中から選定すべきだと考えられる。
Rocky Linux Rocky Linux</description>
    </item>
    
    <item>
      <title>【vscode】devcontainer最高やぞ、という話</title>
      <link>https://pages.shibadog.net/posts/015_vscode_devcontainer01/</link>
      <pubDate>Tue, 27 Dec 2022 00:00:00 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/015_vscode_devcontainer01/</guid>
      <description>目次
なんぞ？ 何がいいねん 使い方 ベースイメージ featureについて 拡張機能も宣言しよう 事前処理を記述する オリジナルfeatureの作成 テンプレートからの新規リポジトリ 開発環境構築 テストを試す GitHub Action 実際に組み込んでみる なんぞ？ Microsoft製のOSSエディタであるvscodeに追加された便利機能について。
端的に言うと、コンテナ環境に開発環境を構築し、直接vscodeで開くことで開発専用のsandbox内で開発ができるという代物。
決まり事である、 .devcontainer というフォルダや json の定義に開発環境の状態を記述することで、どの端末でも同一の環境をコンテナ上に作成し開発を行うことができる。
各開発者の環境固有の設定などを排除することで環境差異を極力減らす事を目的としている。
こっからポエム
各個人の開発環境に対してこだわりを持っていくことはどの開発者でもわかると思う。しかし、開発環境の多機能化が進んでしまったことで開発用IDEの設定というものはかなり煩雑になってきている。いろいろな端末で自身のIDEの設定を同期させる拡張機能などは存在するもの、用途によって必要となる拡張機能は様々となる。必要な時に必要な拡張機能やツールを使うことでシンプルに環境を保つことは困難になる一方で、これを解決するため、各リポジトリ事に開発環境を持つ思想が生まれるのは必然ではないか。もはや、自身の環境は常に空っぽで、リポジトリ事に開発環境・ツールを整備すればすべてがシンプルになるのではないか？！と思った次第で、とても感銘を受けているからこれを書き始めた（オタク特有の早口）。
何がいいねん 上で書いてしまっているが、開発者が持つ個人端末固有の設定に依存せず、常に同一の環境で開発を行事ができるため、ハマりずらくなる。
また、クラウド上に開発環境を作成し、ブラウザで開発を行うスタイルの開発環境では、クラウドに作成する開発環境についても同様の設定で動作させることができる（と思う。試してない）。
使い方 以下のようにワークスペース中に devcontainer.json を用意する。
/root/ |-- .devcontainer/ | `-- devcontainer.json |-- src | |-- main | : : ルートまたは、 .devcontainer フォルダ配下に用意することで、vscodeを開いた際に通知にdevcontaerで開きなおすかどうかが聞かれる。
または、このルートフォルダで、 devcontainer open . とコマンドを打つことで直接vscodeで開くことができる。
この devcontainer コマンドは、vscode上のコマンドでインストールすることが可能。
これらは、拡張機能のDev Containersを入れることで有効になる。
ベースイメージ 拡張機能が入っていれば、vscode上で devcontainer.json を生成することも可能。
そちらから作成すれば、ベースイメージは選択式で選ぶこともできる。
このベースイメージは、多種多様のものがあり、シンプルな Ubuntu や、 Alpine から、RubyやJavaなど開発対象の言語に特化したものが存在する。</description>
    </item>
    
    <item>
      <title>急にRubyについて学ぶ</title>
      <link>https://pages.shibadog.net/posts/014_ruby/</link>
      <pubDate>Fri, 01 Oct 2021 00:00:00 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/014_ruby/</guid>
      <description>まずは Javaとの対比が一番わかりやすいのでいったん対比を書く
# 項目 Java Ruby 備考 1 実行 java ruby ruby {rubyfile} 2 webフレームワーク spring ほか rails ? 3 テストフレームワーク junit minitest test-unit rspec ruby {testfile} 4 ビルドツール maven gradle rake rake {task} タスクの書き方は後述。 直接実行する場合は、グローバルインストールされていないといけない。 プロジェクト個別にインストールしたrakeを使う場合は以下のような感じ bundle exec rake {task} 5 依存解決 bundle bundle install bundle install &amp;ndash;path gems でプロジェクト個別に依存を収集できる 6 静的解析 findBugs ruboCop いろいろ使い方 シンタックス回り 変数 通常は何も書かずに代入で切るっぽい
variable = &amp;#39;だいにゅうできるよ&amp;#39;; puts variable; ローカル変数を作りたければ以下。
@variable = &amp;#39;ローカル変数！&amp;#39;; puts @variable; クラスの中でクラス変数を定義したい場合はアットが二つ</description>
    </item>
    
    <item>
      <title>spring boot vault</title>
      <link>https://pages.shibadog.net/posts/007_spring-vault/</link>
      <pubDate>Tue, 22 Sep 2020 14:52:00 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/007_spring-vault/</guid>
      <description>やってみた。
Spring Vault
VaultはHashiCorpのプロダクトで、クレデンシャル情報を保持するミドル。
Vaultはコマンドラインでクレデンシャル情報の設定・取得が可能だが、spring boot vaultを使って、Configurationとしてアプリケーションの設定を連携することができる。
spring cloud configと同様に、 bootstrap.properties でVaultへの接続情報を設定することで、読み込みを行うようだ。
application.yml を作成してそこからの設定値読み込みと同時に使用しても問題なく使えた。 (まぁ当たり前か。)
RabbitだのAWSだのElasticsearchだののクレデンシャル情報に対応していると記載されているところから、 bootstrap.properties で操作することで、対応するミドルウェアのクレデンシャル情報を通常の application.yml に設定するのと同様の状態で設定することができるようだ。
どのへんでうれしさを感じるのだろうか？
環境変数で刺すようにするサービスブローカーとどう違うのか。。。？
よりアプリケーションに近い位置でクレデンシャルを設定できるので、良いような悪いような。
コンテナ運用の場合はコンテナ管理ミドルによって環境変数にさしてほしい気もする。
コンテナ管理ミドルを使わずに、手運用デプロイしているときにうれしいとか？
そんな状況で（クレデンシャル管理が）いる？
（そんなならば application.yml にべた書きしてもよいじゃないか）
K8Sな言葉がちょいちょい出てくるので何か想定する運用があるっぽい気もするけど、調べるの飽きてきたのでそろそろ終わる。</description>
    </item>
    
    <item>
      <title>もやもやボール</title>
      <link>https://pages.shibadog.net/posts/006_moyat-ball-star/</link>
      <pubDate>Sun, 28 Jun 2020 09:45:32 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/006_moyat-ball-star/</guid>
      <description>ユニット折り紙 イライラ、もやもやしたときにいつも作るユニット折り紙を並べて行こうという試み。
今回、いつも使っているユニット折り紙の本以外から情報を得て作ったので、作り方を残しておくというのもある。
完成図 作り方 思ったよりも、Draw.ioで折り紙書くの辛かった（何
折り紙の図面は表裏がわかるように範囲色付けとか、変形させた際に微調整をするために、線同士の結合をしたまま移動させるとかの機能があったほうがいい。。。
つまり、ちゃんとしたお絵かきソフトで作ったほうが断然効率がいいということが分かったorz
でもちょっと面白かった</description>
    </item>
    
    <item>
      <title>Browser Cache</title>
      <link>https://pages.shibadog.net/posts/011_browser_cache/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/011_browser_cache/</guid>
      <description>overview 広義の意味では、動作の高速化を図るため、低速・安価な記憶領域から高速・高価な記憶領域へ一時的に情報を保持することを指す（と思う）。
ブラウザキャッシュは主に、ブラウザの描画に使うリソース（HTML、JS、CSS、画像など）を一定期間ローカルに保持することにより、再度ネットワークアクセスを行った際に高速に表示させる機構を指す（はず）
もちろん、昨今使われる動的ページ（Webシステムによるレスポンス）で生成されるHTMLなどのボディ部分に関しては、キャッシュする意味がないため、使用されない。
しかし、ロゴなどの画像を動的に表示することは特定の状況下以外ではまれであるため、静的コンテンツなどと呼び、キャッシュ対象にする。
また、JavaScriptによる動的描画を中心とした動的ページ（シングルページアプリケーション）は、ユーザ側（⇔サーバ側）であるブラウザによる描画になるため、ソースであるJavaScriptは静的コンテンツ扱いが可能になる。
静的コンテンツを高速化する仕組みとして、一種のキャッシュシステムであるCDNというものもの存在する。
ブラウザキャッシュとは異なるが、いわゆる広義のキャッシュという意味では同じ目的の仕組みになる。
これはこれで話が長そうなので、また別途。 参考:さくらのナレッジ - CDNってそもそも何？なんかサーバの負荷が下がるって聞いたんだけど！〜Web制作/運営の幅が広がるCDNを知ろう第1回〜
Browser Cacheのコントロール HTTPのレスポンスヘッダにより、サーバ側からリソースのキャッシュをコントロールすることができる。 https://developer.mozilla.org/ja/docs/Web/HTTP/Headers/Cache-Control
cache-control というヘッダを用いる。
キャッシュを抑止したい場合は、 cache-control: no-store を用いる。
有効期限の設定 様々な指定の仕方で有効期限を設定することができる。 初めてキャッシュを行う時刻からの有効期限秒数を指定する。
特定の日付で有効期限が切れる形式の場合は、このヘッダではなく専用の Expires ヘッダを用いる。
https://developer.mozilla.org/ja/docs/Web/HTTP/Headers/Expires
デフォルトの設定 springMVCで作られたwebシステムはもちろん動的サイトであるため、cacheしたくないはずだが、 デフォルトではどのような動きをするか？
ChromeはDevToolを開いて通信をすると、 cache-control: max-age=0 でリクエストを飛ばすっポイ？
これが原因かわからないけれども常にキャッシュされないし、レスポンスヘッダには cache-control は設定されない。
自分で制御 ResponseEntityオブジェクトでキャッシュコントロールを明示することができる。
@GetMapping(&amp;#34;/users/{name}&amp;#34;) public ResponseEntity&amp;lt;UserDto&amp;gt; getUser(@PathVariable String name) { return ResponseEntity.ok() .cacheControl(CacheControl.maxAge(60, TimeUnit.SECONDS)) .body(new UserDto(name)); } 動的レスポンスをキャッシュさせたい場合はまぁあれだけど、静的コンテンツをthymeleafでドウコウしたときのキャッシュってどうやって制御するんだろう？</description>
    </item>
    
    <item>
      <title>Cookie</title>
      <link>https://pages.shibadog.net/posts/013_cookie/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/013_cookie/</guid>
      <description>overview 正式名称は HTTP Cookie .
端的に言うと、クライアントに情報を保持することができる仕組み。
JavaScriptやサーバからのHTTPレスポンスにより保持させることができる。
また、JavaScriptならロジックで読み取りが可能で、HTTPサーバ通信の場合は、許可されているCookieを通信の際に自動付与して送信する。
ServerからCookieを設定する場合は、レスポンスヘッダに Set-Cookei を付与することで設定できる。
JavaScriptの場合 document.cookie でアクセスできる。
保持可能情報 # 項目 内容 1 name Cookie名（キー） 2 value Cookieがもつ値 3 Domain 発行元ドメイン 4 Path パス 5 Expires 有効期限 6 max-age 有効期限２（寿命） 7 HttpOnly サーバ送信にしか使えなくする。つまりJavaScriptから見れなくする 8 Secure HTTPS(SSL)通信の場合だけ送信するようにする。 9 SameSite None、Lax、Strictがあり、ドメイン間のCookie参照に関する設定となる 10 Priority 容量による制限でCookieを削除する際に消す際の優先度となる。低いほうから消す。 SameSiteとは？ 設定値 効果 Strict Aサイトに対し、Bサイトからどのようなリクエストがあっても、発行したサイトでCookieヘッダーに含めない（Cookieを使用しない） Lax Aサイトに対し、BサイトからのGETリクエストのみCookieヘッダーへ含める（Cookieを使用する）。これ以外のリクエストは含めない None Aサイトに対し、Bサイトからどのようなリクエストがあっても、発行したサイトでCookieヘッダーに含める (Cookieを使用する) 参考資料 Qiita - Chrome 80が密かに呼び寄せる地獄 ～ SameSite属性のデフォルト変更を調べてみた(@ahera) 有効期限 Session Cookie 有効期限など指定しない場合は大体のブラウザがこの挙動となる。
ブラウザ（タブ？）が閉じられない間は保持し続ける。</description>
    </item>
    
    <item>
      <title>JavaFX 入門</title>
      <link>https://pages.shibadog.net/posts/012_javafx01/</link>
      <pubDate>Sat, 23 May 2020 00:00:00 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/012_javafx01/</guid>
      <description>overview C#でWPFを使った開発を経験しているが、Javaでも同様の仕組みであるJavaFXが出たので、JavaFXが気になって仕方がない。
いまさらながら、調べてみようという話
現在SpringによるWebバックエンド開発が主な仕事なので、その辺の知識を生かしてうまいことJavaFXに適用できないかも模索してみる。
完全にJavaFXは初心者である
環境構築 JavaFXはJava11から本体から切り離された様子。 （この辺深堀している記事がありそうなので探そう。。。）
取り急ぎ、ググった結果ぱっと出てきたGluonが出しているOpenJavaFX11の環境構築を行った。
開発環境はもちろんWindowsなので、パッケージ管理にScoopを使う。
scoopの公式拡張bucketのjava bucketを追加してインストールする。
PS&amp;gt; scoop bucket add java PS&amp;gt; scoop update PS&amp;gt; scoop search javajfx &amp;#39;java&amp;#39; bucket: gluon-openjfx-jmods-ea (15-5) gluon-openjfx-jmods-lts (11.0.2) gluon-openjfx-jmods (14.0.1) gluon-openjfx-sdk-ea (15-5) gluon-openjfx-sdk-lts (11.0.2) gluon-openjfx-sdk (14.0.1) PS&amp;gt; scoop install gluon-openjfx-sdk-lts もちろん、javaも必要なのでインストールしておく
PS&amp;gt; scoop install openjdk11 あと、画面を作成するためのXMLエディタとしてscene builderというものが存在する。
WPFの画面作成のアレと同じことができる。
これはscoopに存在しなかったので、適当に自分でscoop bucketを作ったので追加してインストール
PS&amp;gt; scoop bucket add my-bucket https://github.com/shibadog/my-bucket.git PS&amp;gt; scoop update PS&amp;gt; scoop search scene-builder &amp;#39;my-bucket&amp;#39; bucket: gluon-scene-builder (11.0.0) PS&amp;gt; scoop install gluon-scene-builder これで実行環境と開発SDKのインストール完了。</description>
    </item>
    
    <item>
      <title>暗号化/ハッシュ化について調べた</title>
      <link>https://pages.shibadog.net/posts/003_encript/</link>
      <pubDate>Mon, 04 Nov 2019 22:54:02 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/003_encript/</guid>
      <description>何もできなかったから過去書いたネタを転載（ぉ
暗号化アルゴリズム 暗号化と複合 暗号化は誰でもアクセス可能なパブリックな場所でデータを転送する際に、第三者にデータを盗み見されたり、改ざんされないようにデータを守るために用いられる。
暗号化や複合は、暗号化アルゴリズムと鍵によって行われる。
2種類の暗号化方式 暗号化アルゴリズムには大きく分けて2種類のものがある。
共通鍵暗号 公開鍵暗号 共通鍵暗号 この方式は、直観的に理解しやすい。
いわゆる現実で用いる「鍵」と同様の方法で、一つの「鍵」を用いて鍵をかける（暗号化）ことができ、さらに同じ「鍵」で鍵を開ける（複合化）できる。
また、この「鍵」を「共通鍵」と呼ぶ。
欠点と相手は、暗号化する側と、複合化する側が異なる場合に同一の「共通鍵」をそれぞれが保有している必要がある。
これは、「共通鍵」を他人が知り得てしまった場合は、その他人が暗号文を解読できてしまうというリスクが発生する。
公開鍵方式 この方式は、少し現実で表現しにくい。
二つの鍵を用意し、それぞれ、「暗号化用」と「複合化用」とする。
「暗号化用」の鍵を「公開鍵」と呼び、「複合化用」の鍵を「秘密鍵」と呼ぶ。
使用するときは、複合化する側が2つの鍵を生成し、「公開鍵」を暗号化する側に渡す。
渡された暗号化する側が「公開鍵」で暗号化を行った後、複合化する側に暗号文を渡す。
複合化する側は「秘密鍵」を用いて暗号文を複合化できる。
この方式の特徴は、「公開鍵」で暗号化したものは「秘密鍵」でのみ複合化できるということで、かつ、「公開鍵」を用いて「秘密鍵」を推測することができないことである。
「公開鍵」を知り得ても暗号化はできても複合化ができないため、必ず「秘密鍵」を持っているものしか暗号文を解読することはできない。
欠点としては、共通鍵方式と比べると処理（暗号化・複合化）の速度が遅い。
ハイブリット方式 それぞれの方式には利点・欠点がありそれを補完するためにはブリット方式が存在する。
ハイブリット方式では、データの暗号化には「共通鍵方式」を用い、この「共通鍵」を受け渡す際に「公開鍵方式」で暗号化を行うというものである。
「共通鍵」の漏えいリスクを「公開鍵方式」で担保し、高速な「共通鍵方式」のアルゴリズムでデータを担保するという手法。
共通鍵方式の中での2種類の方式 共通鍵方式の中で、その手法を大きく2つに分けることができる。
それが以下の2つの種類の暗号化方式である。
ブロック暗号 ストリーム暗号 ブロック暗号 ブロック暗号は、暗号化対象の平文データを一定の長さのブロックに分割して暗号化を行う手法である。
通常、平文データは1byte単位の可変長であるが、1byteごとに1byteの暗号文としていた場合は256通りのパターンでしかないため、簡単に解読されてしまう。
これを防ぐために、8byte（64bit）や、32byte（256bit）といった、より大きな「ブロック」ごとにまとめて暗号化する方式で解読を難しくしている。
ストリーム暗号 ブロック暗号では、ブロック毎に暗号化をすることで1byte毎の暗号化よりも解読を難しくしているが、結局ブロック長が短ければパターン数が少なく解読の難易度も下がってしまう問題は変わらない。
ブロック長を十分な長さにしたとしても、過去あった暗号化方式であるDESでも起こったように、コンピュータの性能向上によって脆弱なアルゴリズムになってしまう。
そこで、任意長の鍵ストリーム列を生成させ、これと入力の平文を演算させる「ストリーム暗号」が考え出された。
これは、1bitや1byte単位でデータを暗号化でき、かつ、パターンを十分に増やせる。
また、対象の平文の長さを気にしなくて済むため、SSL（HTTPS）や無線LAN（WEP）など、ネットワークトラフィックを暗号化するために利用されている。
暗号化アルゴリズムの種類 暗号化アルゴリズム一覧 # 方式 暗号化方式 暗号アルゴリズム 信頼度 規格 備考 1 共通鍵 ブロック DES 低 RFC 2451 2 共通鍵 ブロック AES 中 3 共通鍵 ブロック Rijndael 高 4 共通鍵 ブロック Triple-DES 中 5 共通鍵 ブロック RC2 低 RFC 2268 6 共通鍵 ストリーム RC4 低 RFC 7465 7 公開鍵 - RSA 高 大きな数の素因数分解問題 8 公開鍵 - El Gamal 高 離散対数問題 9 公開鍵 - ECC 高 離散対数暗号方式に楕円曲線の点のグループを適用させた方式 暗号利用モード (Block cipher modes of opration) 暗号化のアルゴリズムとは別に、暗号化を行う手順についての規格（？）。</description>
    </item>
    
    <item>
      <title>Hystrixを説明してみた２</title>
      <link>https://pages.shibadog.net/posts/002_hystrix_02/</link>
      <pubDate>Sat, 26 Oct 2019 13:17:15 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/002_hystrix_02/</guid>
      <description>Hystrixを説明してみた の続き
Hystrixの機能 Hystrixの機能紹介をしてみる。
コマンド隔離 コマンドエラー検知 例外ハンドリング タイムアウトハンドリング コマンド同時実行数制限 コマンド隔離 Hystrixではコマンドの隔離が行える。
具体的には、指定したメソッド一つが隔離対象となり、別名で隔離したメソッドと影響しあわないようにできる。
例えば、以下のように2つのコマンドを定義したアプリの場合。 コマンドAからアクセスするAPIAがタイムアウトを頻発するような状況になってしまったとすると、
コマンドAが即エラーを返すようなることで、リクエスト処理スレッドが占有されず、コマンドBは正常に処理が行われる。
コマンドエラー検知 コマンド内で実行される処理でExceptionが発生した場合には、このExceptionを検知してフォールバック処理を行うことができる。
また、コマンド内の処理のタイムアウトを測ることができ、指定時間を過ぎた場合に、HystrixのExceptionを発生させることができる。
timeInMillisecondsの秒数内に、numBuckets分の記録用の箱があるイメージ。 例えば、10,000msで10Bucketsの場合、集計範囲は1,000msになる。
circuitBreaker.errorThresholdPercentageで設定した割合でSuccess以外のエラー数となった場合に、ショートサーキット状態となる。
参考：GitHub - Netflix/Hystrix wiki
コマンド同時実行数制御 隔離されたコマンドは同時実行数の制御が行える。
Hystrixは隔離方式を2種類用意しており、デフォルトでは独立Threadによる制御を行う。
もう一つの制御方法として、セマフォ方式を持っている。
若干飽きて適当になった（ぇ
いったんこれまでにしておく。</description>
    </item>
    
    <item>
      <title>Hystrixを説明してみた</title>
      <link>https://pages.shibadog.net/posts/001_hystrix_01/</link>
      <pubDate>Sun, 20 Oct 2019 21:10:22 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/001_hystrix_01/</guid>
      <description>Hystrixとは Netflixが開発したOSSで、Circuit Breakerの実装。
Circuit Breakerとは、マイクロサービスで開発されたアプリケーション同士が、一つのアプリの障害で連鎖的に障害を発生させる状態を防止するための、ブレーカー的役割をする機能のこと。
後続のアプリケーションが障害を起こした場合、当該アプリで即エラーを返すことでリクエストの流入を抑える。
例えば、一番後続のアプリが障害を起こして、応答がなくなる。
リクエストが流れ続けるため、障害を起こしたアプリを呼び出す前段のアプリが引きずられ、スレッド枯渇やGC頻発による応答不能が発生する（ことがある）。
さらに、これを呼び出すアプリが同様に障害を起こすことで、正常なアプリへの呼び出しも行われなくなり、全体が障害となってしまう。
もし、Hystrixがアプリに組み込まれていた場合。
やはり、最下層のアプリに障害が発生し。。。
しかし、前段のアプリで、障害を検知して後続が障害の場合のロジックを通って
これによって、後続が障害により連続でエラーを返す状態になった場合にも、後続へのリクエストを中止し、負荷をかけないようにしたうえで、異常状態の対処を行う。
これが相当に便利であり、しかも後続への無駄な負荷をかけずにすむという代物でした。
今回はここまで。</description>
    </item>
    
    <item>
      <title>hugoにgoogleアナリティクスを導入</title>
      <link>https://pages.shibadog.net/posts/hugo_analytics/</link>
      <pubDate>Thu, 17 Oct 2019 09:55:20 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/hugo_analytics/</guid>
      <description>とりあえずgoogle analyticsが標準対応との記述を公式ドキュメントで見つけたのでやっておく。
1. google analyticsにログイン 2. 新規プロパティを作成 ハマったこと ウェブを選択。
アプリとウェブだとうまくできなかった（よくよめよ）
3. トラッキングIDをコピー プロパティのメニューから選ぶ
4. config.toml に追加 baseURL = &amp;#34;https://shibadog.github.io/&amp;#34; languageCode = &amp;#34;ja-jp&amp;#34; title = &amp;#34;shibadog site&amp;#34; theme = &amp;#34;hermit&amp;#34; googleAnalytics = &amp;#34;UA-999999999-9&amp;#34; [author] name = &amp;#34;shibadog&amp;#34; : : 参考 AGO&amp;rsquo;s page - hugoにgoogle アナリティクスを導入した話 なかけんのHugoノート - 画像を追加しよう </description>
    </item>
    
    <item>
      <title>My First Post</title>
      <link>https://pages.shibadog.net/posts/my-first-post/</link>
      <pubDate>Tue, 15 Oct 2019 23:52:59 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/my-first-post/</guid>
      <description>ブログをまたやりたいと思い、 Hugo という静的サイトジェネレータと GitHub Pages を使って作ってみた。
3日坊主にならないことを祈る。
しかし、このHugoというやつ結構楽しい。 まずはこれを使いこなせるようになりたい。。。</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>https://pages.shibadog.net/about-hugo/</link>
      <pubDate>Tue, 15 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://pages.shibadog.net/about-hugo/</guid>
      <description>経験言語 Java バックエンドWebシステム（リプレース開発） Swingを使ったクラサバ（リプレース開発） Spring Boot マイクロサービス（新規開発） C# Webシステム（保守・運用開発） WPFクラサバ（保守・運用開発） VBA/VBS Excel/Accessツール（設計・開発・導入・保守） バッチ（運用開発） PHP フレームワークなしのWebシステム（運用開発） テンプレートエンジンを使ったWebシステム（新規開発・運用保守） バッチ（新規開発） JavaScript WebPack + Vue.js 動的ページ（運用開発） JQueryの簡単なページ（新規開発） ミドルウェア Elasticsearch Elasticsearchを使ったログ収集 File =&amp;gt; Fluentd =&amp;gt; Elasticsearch =&amp;gt; kibana DB =&amp;gt; Logstash =&amp;gt; Elasticsearch =&amp;gt; kibana 資料 第39回Elasticsearch勉強会 2020.12.17 ecs-logging-javaつかってみた by @shibadog ElasticON Solution Seminar 2022.07.21 構造化ログ × elastic-agent by @shibadog </description>
    </item>
    
  </channel>
</rss>
