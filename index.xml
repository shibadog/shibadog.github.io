<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>shibadog site</title>
    <link>https://pages.shibadog.net/</link>
    <description>Recent content on shibadog site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Wed, 17 May 2023 00:00:00 +0900</lastBuildDate><atom:link href="https://pages.shibadog.net/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>spring boot 3 trace</title>
      <link>https://pages.shibadog.net/posts/008_survery_results/</link>
      <pubDate>Wed, 17 May 2023 00:00:00 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/008_survery_results/</guid>
      <description>背景 spring boot3になってからtraceの構成が変わった。
sleuth から micrometer observationを使う用に代わり、opentelemetryが入ってきて関係性が変わったのでそれを把握したい。
micrometer observationの解説は優秀なブログがすでにあるのでそちらに任せることにする。
https://programacho.com/blog/a10b96ec9d79/
ここでは、このmicrometerの裏側を把握することを目的とする。
全体感から見た各種ライブラリの役割 ▲ なにかのdiagramのルールにのっとって書いているわけではなく、雰囲気で矢印と図形の形を変えている。
意味はあるが公のルールではないのでご注意。
tracer layerの詳細 この領域はトレーサー層と呼ぶらしい。
ここは、exporter（braveではreporter）を使って実際のトレース情報を伝送する部分の実装であったり、アプリケーション間のトレース情報をつなぐための処理を行う実装が存在する。
braveはもともとのspring cloudに存在する実装であり、zipkinのb3ヘッダのみに対応している。
opentelemetryでは、opentelemetryが定義する伝送プロトコル（なんだっけ？）とb3のどちらにも対応しており、ここをpropagatorと呼んでおり差し替え可能となっている。
w3c → W3CTraceContextPropagator b3 → B3Propagator opentelemetryを使った場合のexporter layer詳細 Opentelemetryに対応したトレース参照用のツールはいくつか存在する。
これ以外にも、上記zipkinの例から以下のような構造になっていることが伺える。
参考資料のmakingさんの資料にある通り、spring boot 3.0.Xまでは、exporterのauto configに対応している（つまり何もBean登録しなくても設定だけで使えるやつ）のはzipkinとwavefrontのみとなっている。
しかし、opentelemetry自体はいろいろなexporterに対応しており、自力でBean登録をすることで異なるサービスにtraceを伝送することが可能になっている。
braveを使った場合のexporter layer(reporter)詳細 tracerをopentelemetryではなく従来のbraveを選択することも可能となっている。
この場合でも伝送先を切り替えることが可能となっている。
Opentelemetryに対応しているElastic APMに入れてみる 本リポジトリでは、前章でまとめた依存のうち以下のような組み合わせでアプリケーションを作成している。
tracer layer -&amp;gt; opentelemetry exporter layer -&amp;gt; opentelemetry tracerの記録先は Elastic APMを利用している。
詳しくは ../../pom.xml を参照いただきたいが、traceにかかわる依存は以下の通り。
&amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;io.micrometer&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;micrometer-tracing-bridge-otel&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;io.opentelemetry&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;opentelemetry-exporter-otlp&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; spring bootに関しては、3.0.x系であるため、そのままではopentelemetry exporterのauto configに対応していない。</description>
    </item>
    
    <item>
      <title>CentOSの事情</title>
      <link>https://pages.shibadog.net/posts/009_centos/</link>
      <pubDate>Fri, 03 Mar 2023 00:00:00 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/009_centos/</guid>
      <description>背景 業務で利用するLinux Serverを新規で作成することになった。
既存のLinux Serverの横に追加することになっているため、追加するサーバのOSも併せようと考えたが、現在CentOSはバージョンアップ方針が変わっており、そのまま採用すべきではないのではないか、となった。
適切なOSを選定するとともに、CentOSの事情を把握しておきたいため、調査する。
CentOSの事情 元々の流れ CentOSは Red Hat Enterprise Linux（以降RHEL）というディストリビューションの系列に属しており、RHELと機能的に互換性があることを目指したフリーのLinuxディストリビューションである。
RHELに含まれているソフトウェアの中にはOSSで無償公開しているため、これをもとに、商標や商用パッケージをのぞいたものをリビルドして提供している。そのため、「RHELクローン」と呼ばれることもある。(CentOS自体は公式には否定している)
最初期ではRHELを提供するレッドハットは関わっていなかったが、2014年からCentOSを正式に支援していくことを表明していた。
しかし、2020/12/8にCentOSからCentOS Streamに開発の主軸を移動し、CentOS Linux 8のサポートを2021年に停止している。RHEL 9に対応するCentOS Linux 9は提供さず、今後はCentOS Stream 9の提供とする。
Red Hat Enterprise Linux派生ディストリビューション Red Hat Enterprise Linux派生ディストリビューション
RHELには様々なディストリビューションが存在する。大きくは、まず同社がメンテナを行っているFedora Linuxがある。これは、もともとはRHELの無償版であった。
しかし、Fedoraはサポート期間が比較的短く、実験的なリリース方針であったため、長期サポートを望むユーザとしては利用に適していなかった。
RHELはコンパイル済みのものを無償提供していないが、完全なソースコードを公開しているため、これを入手し再コンパイルすることで派生ディストリビューションの作成が行われている。
CentOSのサポート情報 CentOS
Version 完全更新期限 メンテナス更新期限 6 6.10(最終) 2017年 Q2 2020/11/30 7 7.9-2009(最新) 2020年 Q4 2024/06/30 8 8.5.2111(最終) 2021年12月 2021/12/31 CentOS Stream CentOS StreamはRHELとFedora Linuxの中間を目指したディストリビューション。
Fedoraは実験的なリリースを取り込み、RHELの将来のメジャーリリースのベースとなるアップストリームプロジェクトであったが、CentOS StreamはRHELの次のバージョンとなる変更を取り入れたRHELのプレビューとなる。
このような性質の変更があったため、重要なビジネスアプリケーションやプロダクション環境での使用は推奨されておらずRHELが進められる。
元々のCentOSの性質としては、他のRHELと同様にコードのリビルドから生成されたものであり、個別メンテナンスであったため、今回の変更で性質ががらりと変わる。
やはり商用利用を考えた場合、（本質的にはRHELを使え、なのだが）あまり利用は推奨されるべきものではなくなるという見解があちらこちらで見られた。
派生ディストリビューションについて CentOSの事情を鑑み（結局ただ乗りになるのだが。。。）、同じ要件をかなえるためのディストリビューションが多数生まれている。
もし、無償版を利用するならばこの中から選定すべきだと考えられる。
Rocky Linux Rocky Linux</description>
    </item>
    
    <item>
      <title>spring boot vault</title>
      <link>https://pages.shibadog.net/posts/007_spring-vault/</link>
      <pubDate>Tue, 22 Sep 2020 14:52:00 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/007_spring-vault/</guid>
      <description>やってみた。
Spring Vault
VaultはHashiCorpのプロダクトで、クレデンシャル情報を保持するミドル。
Vaultはコマンドラインでクレデンシャル情報の設定・取得が可能だが、spring boot vaultを使って、Configurationとしてアプリケーションの設定を連携することができる。
spring cloud configと同様に、 bootstrap.properties でVaultへの接続情報を設定することで、読み込みを行うようだ。
application.yml を作成してそこからの設定値読み込みと同時に使用しても問題なく使えた。 (まぁ当たり前か。)
RabbitだのAWSだのElasticsearchだののクレデンシャル情報に対応していると記載されているところから、 bootstrap.properties で操作することで、対応するミドルウェアのクレデンシャル情報を通常の application.yml に設定するのと同様の状態で設定することができるようだ。
どのへんでうれしさを感じるのだろうか？
環境変数で刺すようにするサービスブローカーとどう違うのか。。。？
よりアプリケーションに近い位置でクレデンシャルを設定できるので、良いような悪いような。
コンテナ運用の場合はコンテナ管理ミドルによって環境変数にさしてほしい気もする。
コンテナ管理ミドルを使わずに、手運用デプロイしているときにうれしいとか？
そんな状況で（クレデンシャル管理が）いる？
（そんなならば application.yml にべた書きしてもよいじゃないか）
K8Sな言葉がちょいちょい出てくるので何か想定する運用があるっぽい気もするけど、調べるの飽きてきたのでそろそろ終わる。</description>
    </item>
    
    <item>
      <title>もやもやボール</title>
      <link>https://pages.shibadog.net/posts/006_moyat-ball-star/</link>
      <pubDate>Sun, 28 Jun 2020 09:45:32 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/006_moyat-ball-star/</guid>
      <description>ユニット折り紙 イライラ、もやもやしたときにいつも作るユニット折り紙を並べて行こうという試み。
今回、いつも使っているユニット折り紙の本以外から情報を得て作ったので、作り方を残しておくというのもある。
完成図 作り方 思ったよりも、Draw.ioで折り紙書くの辛かった（何
折り紙の図面は表裏がわかるように範囲色付けとか、変形させた際に微調整をするために、線同士の結合をしたまま移動させるとかの機能があったほうがいい。。。
つまり、ちゃんとしたお絵かきソフトで作ったほうが断然効率がいいということが分かったorz
でもちょっと面白かった</description>
    </item>
    
    <item>
      <title>暗号化/ハッシュ化について調べた</title>
      <link>https://pages.shibadog.net/posts/003_encript/</link>
      <pubDate>Mon, 04 Nov 2019 22:54:02 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/003_encript/</guid>
      <description>何もできなかったから過去書いたネタを転載（ぉ
暗号化アルゴリズム 暗号化と複合 暗号化は誰でもアクセス可能なパブリックな場所でデータを転送する際に、第三者にデータを盗み見されたり、改ざんされないようにデータを守るために用いられる。
暗号化や複合は、暗号化アルゴリズムと鍵によって行われる。
2種類の暗号化方式 暗号化アルゴリズムには大きく分けて2種類のものがある。
共通鍵暗号 公開鍵暗号 共通鍵暗号 この方式は、直観的に理解しやすい。
いわゆる現実で用いる「鍵」と同様の方法で、一つの「鍵」を用いて鍵をかける（暗号化）ことができ、さらに同じ「鍵」で鍵を開ける（複合化）できる。
また、この「鍵」を「共通鍵」と呼ぶ。
欠点と相手は、暗号化する側と、複合化する側が異なる場合に同一の「共通鍵」をそれぞれが保有している必要がある。
これは、「共通鍵」を他人が知り得てしまった場合は、その他人が暗号文を解読できてしまうというリスクが発生する。
公開鍵方式 この方式は、少し現実で表現しにくい。
二つの鍵を用意し、それぞれ、「暗号化用」と「複合化用」とする。
「暗号化用」の鍵を「公開鍵」と呼び、「複合化用」の鍵を「秘密鍵」と呼ぶ。
使用するときは、複合化する側が2つの鍵を生成し、「公開鍵」を暗号化する側に渡す。
渡された暗号化する側が「公開鍵」で暗号化を行った後、複合化する側に暗号文を渡す。
複合化する側は「秘密鍵」を用いて暗号文を複合化できる。
この方式の特徴は、「公開鍵」で暗号化したものは「秘密鍵」でのみ複合化できるということで、かつ、「公開鍵」を用いて「秘密鍵」を推測することができないことである。
「公開鍵」を知り得ても暗号化はできても複合化ができないため、必ず「秘密鍵」を持っているものしか暗号文を解読することはできない。
欠点としては、共通鍵方式と比べると処理（暗号化・複合化）の速度が遅い。
ハイブリット方式 それぞれの方式には利点・欠点がありそれを補完するためにはブリット方式が存在する。
ハイブリット方式では、データの暗号化には「共通鍵方式」を用い、この「共通鍵」を受け渡す際に「公開鍵方式」で暗号化を行うというものである。
「共通鍵」の漏えいリスクを「公開鍵方式」で担保し、高速な「共通鍵方式」のアルゴリズムでデータを担保するという手法。
共通鍵方式の中での2種類の方式 共通鍵方式の中で、その手法を大きく2つに分けることができる。
それが以下の2つの種類の暗号化方式である。
ブロック暗号 ストリーム暗号 ブロック暗号 ブロック暗号は、暗号化対象の平文データを一定の長さのブロックに分割して暗号化を行う手法である。
通常、平文データは1byte単位の可変長であるが、1byteごとに1byteの暗号文としていた場合は256通りのパターンでしかないため、簡単に解読されてしまう。
これを防ぐために、8byte（64bit）や、32byte（256bit）といった、より大きな「ブロック」ごとにまとめて暗号化する方式で解読を難しくしている。
ストリーム暗号 ブロック暗号では、ブロック毎に暗号化をすることで1byte毎の暗号化よりも解読を難しくしているが、結局ブロック長が短ければパターン数が少なく解読の難易度も下がってしまう問題は変わらない。
ブロック長を十分な長さにしたとしても、過去あった暗号化方式であるDESでも起こったように、コンピュータの性能向上によって脆弱なアルゴリズムになってしまう。
そこで、任意長の鍵ストリーム列を生成させ、これと入力の平文を演算させる「ストリーム暗号」が考え出された。
これは、1bitや1byte単位でデータを暗号化でき、かつ、パターンを十分に増やせる。
また、対象の平文の長さを気にしなくて済むため、SSL（HTTPS）や無線LAN（WEP）など、ネットワークトラフィックを暗号化するために利用されている。
暗号化アルゴリズムの種類 暗号化アルゴリズム一覧 # 方式 暗号化方式 暗号アルゴリズム 信頼度 規格 備考 1 共通鍵 ブロック DES 低 RFC 2451 2 共通鍵 ブロック AES 中 3 共通鍵 ブロック Rijndael 高 4 共通鍵 ブロック Triple-DES 中 5 共通鍵 ブロック RC2 低 RFC 2268 6 共通鍵 ストリーム RC4 低 RFC 7465 7 公開鍵 - RSA 高 大きな数の素因数分解問題 8 公開鍵 - El Gamal 高 離散対数問題 9 公開鍵 - ECC 高 離散対数暗号方式に楕円曲線の点のグループを適用させた方式 暗号利用モード (Block cipher modes of opration) 暗号化のアルゴリズムとは別に、暗号化を行う手順についての規格（？）。</description>
    </item>
    
    <item>
      <title>Hystrixを説明してみた２</title>
      <link>https://pages.shibadog.net/posts/002_hystrix_02/</link>
      <pubDate>Sat, 26 Oct 2019 13:17:15 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/002_hystrix_02/</guid>
      <description>Hystrixを説明してみた の続き
Hystrixの機能 Hystrixの機能紹介をしてみる。
コマンド隔離 コマンドエラー検知 例外ハンドリング タイムアウトハンドリング コマンド同時実行数制限 コマンド隔離 Hystrixではコマンドの隔離が行える。
具体的には、指定したメソッド一つが隔離対象となり、別名で隔離したメソッドと影響しあわないようにできる。
例えば、以下のように2つのコマンドを定義したアプリの場合。 コマンドAからアクセスするAPIAがタイムアウトを頻発するような状況になってしまったとすると、
コマンドAが即エラーを返すようなることで、リクエスト処理スレッドが占有されず、コマンドBは正常に処理が行われる。
コマンドエラー検知 コマンド内で実行される処理でExceptionが発生した場合には、このExceptionを検知してフォールバック処理を行うことができる。
また、コマンド内の処理のタイムアウトを測ることができ、指定時間を過ぎた場合に、HystrixのExceptionを発生させることができる。
timeInMillisecondsの秒数内に、numBuckets分の記録用の箱があるイメージ。 例えば、10,000msで10Bucketsの場合、集計範囲は1,000msになる。
circuitBreaker.errorThresholdPercentageで設定した割合でSuccess以外のエラー数となった場合に、ショートサーキット状態となる。
参考：GitHub - Netflix/Hystrix wiki
コマンド同時実行数制御 隔離されたコマンドは同時実行数の制御が行える。
Hystrixは隔離方式を2種類用意しており、デフォルトでは独立Threadによる制御を行う。
もう一つの制御方法として、セマフォ方式を持っている。
若干飽きて適当になった（ぇ
いったんこれまでにしておく。</description>
    </item>
    
    <item>
      <title>Hystrixを説明してみた</title>
      <link>https://pages.shibadog.net/posts/001_hystrix_01/</link>
      <pubDate>Sun, 20 Oct 2019 21:10:22 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/001_hystrix_01/</guid>
      <description>Hystrixとは Netflixが開発したOSSで、Circuit Breakerの実装。
Circuit Breakerとは、マイクロサービスで開発されたアプリケーション同士が、一つのアプリの障害で連鎖的に障害を発生させる状態を防止するための、ブレーカー的役割をする機能のこと。
後続のアプリケーションが障害を起こした場合、当該アプリで即エラーを返すことでリクエストの流入を抑える。
例えば、一番後続のアプリが障害を起こして、応答がなくなる。
リクエストが流れ続けるため、障害を起こしたアプリを呼び出す前段のアプリが引きずられ、スレッド枯渇やGC頻発による応答不能が発生する（ことがある）。
さらに、これを呼び出すアプリが同様に障害を起こすことで、正常なアプリへの呼び出しも行われなくなり、全体が障害となってしまう。
もし、Hystrixがアプリに組み込まれていた場合。
やはり、最下層のアプリに障害が発生し。。。
しかし、前段のアプリで、障害を検知して後続が障害の場合のロジックを通って
これによって、後続が障害により連続でエラーを返す状態になった場合にも、後続へのリクエストを中止し、負荷をかけないようにしたうえで、異常状態の対処を行う。
これが相当に便利であり、しかも後続への無駄な負荷をかけずにすむという代物でした。
今回はここまで。</description>
    </item>
    
    <item>
      <title>hugoにgoogleアナリティクスを導入</title>
      <link>https://pages.shibadog.net/posts/hugo_analytics/</link>
      <pubDate>Thu, 17 Oct 2019 09:55:20 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/hugo_analytics/</guid>
      <description>とりあえずgoogle analyticsが標準対応との記述を公式ドキュメントで見つけたのでやっておく。
1. google analyticsにログイン 2. 新規プロパティを作成 ハマったこと ウェブを選択。
アプリとウェブだとうまくできなかった（よくよめよ）
3. トラッキングIDをコピー プロパティのメニューから選ぶ
4. config.toml に追加 baseURL = &amp;#34;https://shibadog.github.io/&amp;#34; languageCode = &amp;#34;ja-jp&amp;#34; title = &amp;#34;shibadog site&amp;#34; theme = &amp;#34;hermit&amp;#34; googleAnalytics = &amp;#34;UA-999999999-9&amp;#34; [author] name = &amp;#34;shibadog&amp;#34; : : 参考 AGO&amp;rsquo;s page - hugoにgoogle アナリティクスを導入した話 なかけんのHugoノート - 画像を追加しよう </description>
    </item>
    
    <item>
      <title>ブログのネタブログ</title>
      <link>https://pages.shibadog.net/posts/blog_neta/</link>
      <pubDate>Wed, 16 Oct 2019 22:12:21 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/blog_neta/</guid>
      <description>ブログを書きたい気持ちはある。（ともにネタもいくつか考えられはする）
がしかし、どこから攻めるか、はたまた思いつくままに初めて尻すぼみで終わるのではないかという不安がある。
これの対策として、ブログにしたい（つまり勉強したい）ネタを並べて置くことにする。
（つまり、「今興味があること」になるわけだ）
Java系 Hystrix（というはサーキットブレーカー）についての動き説明 Resilience4jの動きの調査 Spring Boot サーキットブレーカーの調査 WebClient系の動き調査 リトライ系の動きの調査 Spring以外のフレームワーク（Javaに限る）の調査 インフラ寄り くーばねーちすの調査 DockerとDocker Compose周り。あと運用。 TCP/IPやHTTPとかSSLとか 他ジャンル らずぱい hugoのカスタマイズ・使いこなし系の話 アルゴリズム 暗号化まわり 圧縮回り GCアルゴリズム 次に、書こうと思っていつも断念する原因の調査（これをしないと進めない気がするから）
なぜ、ブログを書こうとして不安に陥るのか？
調べると世の中大体、誰かが同じようなことをしている でも、複数の情報を合わせないと目的のものにならない 結局自分の言葉にしないと理解が進まない よし、OK 自分が書くより他人が書いたもののほうがわかりやすいし正確 結局自分の言葉にしないと理解が進まない 間違っていることに気づいたら直せばよい。 よし、OK ディテールにこだわってなかなか完成しない 調査内容にコンセプトを作り、小さく初めて積み上げる！ 途中まで進めてもいいんだよ、間違っていると感じたらやり直せばよいじゃないか。 よし、OK 誰の役にも立たないでしょう？すでにあるわけだし正確でもなく不十分だったりするわけだから やらないよりはやったほうが良い。 少なくとも自分のためにはなるはず よし、OK 不安になったら見直そう。
あと、大得意の3日坊主にならないために、一週間に一回は何かしらを進めるようにしよう。 そして途中でもここに書き留めていこうと心に決める（ほんとかよ）</description>
    </item>
    
    <item>
      <title>My First Post</title>
      <link>https://pages.shibadog.net/posts/my-first-post/</link>
      <pubDate>Tue, 15 Oct 2019 23:52:59 +0900</pubDate>
      
      <guid>https://pages.shibadog.net/posts/my-first-post/</guid>
      <description>ブログをまたやりたいと思い、 Hugo という静的サイトジェネレータと GitHub Pages を使って作ってみた。
3日坊主にならないことを祈る。
しかし、このHugoというやつ結構楽しい。 まずはこれを使いこなせるようになりたい。。。</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>https://pages.shibadog.net/about-hugo/</link>
      <pubDate>Tue, 15 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://pages.shibadog.net/about-hugo/</guid>
      <description>経験言語 Java バックエンドWebシステム（リプレース開発） Swingを使ったクラサバ（リプレース開発） Spring Boot マイクロサービス（新規開発） C# Webシステム（保守・運用開発） WPFクラサバ（保守・運用開発） VBA/VBS Excel/Accessツール（設計・開発・導入・保守） バッチ（運用開発） PHP フレームワークなしのWebシステム（運用開発） テンプレートエンジンを使ったWebシステム（新規開発・運用保守） バッチ（新規開発） JavaScript WebPack + Vue.js 動的ページ（運用開発） JQueryの簡単なページ（新規開発） ミドルウェア Elasticsearch Elasticsearchを使ったログ収集 File =&amp;gt; Fluentd =&amp;gt; Elasticsearch =&amp;gt; kibana DB =&amp;gt; Logstash =&amp;gt; Elasticsearch =&amp;gt; kibana 資料 第39回Elasticsearch勉強会 2020.12.17 ecs-logging-javaつかってみた by @shibadog ElasticON Solution Seminar 2022.07.21 構造化ログ × elastic-agent by @shibadog </description>
    </item>
    
  </channel>
</rss>
